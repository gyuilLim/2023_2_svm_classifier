{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = './archive/fashion-mnist_train.csv'\n",
    "test = './archive/fashion-mnist_private_test2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = pd.read_csv(train)\n",
    "original_train_data = original_train.drop('label', axis=1)\n",
    "original_train_labels = original_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60000it [00:17, 3452.27it/s]\n"
     ]
    }
   ],
   "source": [
    "image_list = [[] for i in range(10)]\n",
    "\n",
    "for i in tqdm(original_train.iloc):\n",
    "    image = np.array(i.drop('label')).reshape(28,28)\n",
    "    image_list[i['label']].append(image)\n",
    "    \n",
    "# image_list.shape = (10, 6000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(91)\n",
    "\n",
    "aug_image_list = [[] for i in range(10)]\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    c = 0\n",
    "    if i == 0 or i == 5 or i == 8:\n",
    "        max_num = 4000\n",
    "        rand_num = 7\n",
    "    else :\n",
    "        max_num = 3000\n",
    "        rand_num = 6\n",
    "    for j in range(len(image_list[0])) :\n",
    "        num = random.randrange(1, 11)\n",
    "        if c == max_num :\n",
    "            break\n",
    "        if num <= rand_num :\n",
    "            image = image_list[i][j]\n",
    "            temp_image = Image.fromarray(image.astype(np.uint8))\n",
    "            # # 랜덤 증강\n",
    "            new_image = temp_image.transform(temp_image.size, Image.AFFINE, (1, 0, -1, 0, 1, -1))\n",
    "            new_image = np.array(new_image)\n",
    "            aug_image_list[i].append(list(new_image))\n",
    "            c += 1\n",
    "        else :\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_3000_list = []\n",
    "aug_4000_list = []\n",
    "for i in aug_image_list :\n",
    "    if len(i) == 3000 :\n",
    "        aug_3000_list.append(i)\n",
    "    elif len(i) == 4000 :\n",
    "        aug_4000_list.append(i)\n",
    "\n",
    "aug_3000_list = np.array(aug_3000_list)\n",
    "aug_4000_list = np.array(aug_4000_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels4000 = [0, 5, 8]\n",
    "labels3000 = [1, 2, 3, 4, 6, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_set_3000 = []\n",
    "new_data_set_4000 = []\n",
    "\n",
    "for class_index, image_list in zip(labels3000, aug_3000_list) :\n",
    "    for image in image_list :\n",
    "        label_pixel = [class_index] + list(image.flatten())\n",
    "        new_data_set_3000.append(label_pixel)\n",
    "        \n",
    "\n",
    "for class_index, image_list in zip(labels4000, aug_4000_list) :\n",
    "    for image in image_list :\n",
    "        label_pixel = [class_index] + list(image.flatten())\n",
    "        new_data_set_4000.append(label_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21000, 785), (12000, 785))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_set_3000 = np.array(new_data_set_3000)\n",
    "new_data_set_4000 = np.array(new_data_set_4000)\n",
    "\n",
    "np.array(new_data_set_3000).shape, np.array(new_data_set_4000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 785)\n",
      "(93000, 785)\n"
     ]
    }
   ],
   "source": [
    "merged_aug_list = np.concatenate((new_data_set_3000, new_data_set_4000), axis=0)\n",
    "print(merged_aug_list.shape)\n",
    "merged_image_list = np.concatenate((np.array(original_train), merged_aug_list), axis=0)\n",
    "print(merged_image_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=list(original_train.columns))\n",
    "\n",
    "csv_file_path = './aug_train.csv'\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # 각 행을 CSV 파일에 쓰기\n",
    "    for row in merged_image_list:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('aug_train.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    header = next(reader, None)\n",
    "\n",
    "    rows = list(reader)\n",
    "\n",
    "random.shuffle(rows)\n",
    "\n",
    "with open('./aug_fashion-mnist_train.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    if header:\n",
    "        writer.writerow(header)\n",
    "\n",
    "    writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0, 2, 4, 6 라벨 제외 1로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./aug_fashion-mnist_train.csv')  \n",
    "\n",
    "labels_to_change = [0, 2, 4, 6]\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x not in labels_to_change else x)\n",
    "\n",
    "df.to_csv('0246_fashion-mnist_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# csv 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = pd.read_csv('./90000_train.csv')\n",
    "train1 = pd.read_csv('./aug_fashion-mnist_train.csv')\n",
    "train2 = pd.read_csv('./046_fashion-mnist_train.csv')\n",
    "public = pd.read_csv('/home/vision/gyuil/3-2/머신러닝/svm/archive/fashion-mnist_public_test.csv')\n",
    "test = pd.read_csv(test)\n",
    "\n",
    "#train\n",
    "train0_data = train0.drop('label', axis=1)\n",
    "train0_labels = train0['label']\n",
    "train1_data = train1.drop('label', axis=1)\n",
    "train1_labels = train1['label']\n",
    "train2_data = train2.drop('label', axis=1)\n",
    "train2_labels = train2['label']\n",
    "\n",
    "\n",
    "\n",
    "#test\n",
    "test_data = test.drop('label', axis=1)\n",
    "\n",
    "#int -> float\n",
    "train0_data = train0_data.astype('float32')\n",
    "train1_data = train1_data.astype('float32')\n",
    "train2_data = train2_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "\n",
    "\n",
    "public = pd.read_csv('/home/vision/gyuil/3-2/머신러닝/svm/archive/fashion-mnist_public_test.csv')\n",
    "public_data = public.drop('label', axis=1)\n",
    "public_labels = public['label']\n",
    "public_data = public_data.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "norm = Normalizer()\n",
    "normalization_train1_data = norm.fit_transform(train1_data)\n",
    "normalization_train0_data = norm.transform(train0_data)\n",
    "normalization_train2_data = norm.transform(train2_data)\n",
    "normalization_test_data = norm.transform(test_data)\n",
    "\n",
    "pca = PCA(n_components=400)\n",
    "pca.fit(normalization_train1_data)\n",
    "\n",
    "pca_norm_train1_data = pca.transform(normalization_train1_data)\n",
    "pca_norm_train2_data = pca.transform(normalization_train2_data)\n",
    "pca_norm_test_data = pca.transform(normalization_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main model train\n",
    "svc = SVC(gamma='scale',kernel='rbf',C=10)\n",
    "svc.fit(pca_norm_train1_data,train1_labels)\n",
    "\n",
    "# inference    \n",
    "svc_preds1 = svc.predict(pca_norm_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub model train\n",
    "svc = SVC(gamma='scale',kernel='rbf',C=10)\n",
    "svc.fit(pca_norm_train2_data,train2_labels)\n",
    "\n",
    "# inference    \n",
    "svc_preds2 = svc.predict(pca_norm_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overwrite Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(svc_preds1)) :\n",
    "    if svc_preds2[i] == 0 or svc_preds2[i] == 4 or svc_preds2[i] == 6 :\n",
    "        svc_preds1[i] = svc_preds2[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_preds_dict = {image : label for image, label in enumerate(svc_preds1)}\n",
    "\n",
    "with open('./final_private.txt', 'w') as file :\n",
    "    for image, label in private_preds_dict.items():\n",
    "        file.write(f'{image:05d} {label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
